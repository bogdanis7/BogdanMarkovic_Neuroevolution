{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "80316452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a8a46f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4af21675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import boston_housing\n",
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "3e5f1c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer:\n",
    "    def __init__(self, activation_function, isLastLayer, weightsMatrix, bias):\n",
    "        self.isLastLayer = isLastLayer\n",
    "        #self.bias = np.random.randn()*(np.sqrt(2.0/self.units))\n",
    "        self.activation_function = activation_function\n",
    "        self.weights = weightsMatrix\n",
    "        self.bias = bias\n",
    "        #self.weights = np.random.uniform(self.input_size, self.units)*(np.sqrt(2.0/self.units)) # He initialization (suitable for relu)\n",
    "    \n",
    "    def get_output(self, layer_input):\n",
    "        self.layer_input = layer_input\n",
    "        \n",
    "        if self.isLastLayer:\n",
    "            return np.dot(self.weights, self.layer_input) + self.bias\n",
    "        else:\n",
    "            a = np.dot(self.weights, self.layer_input) + self.bias\n",
    "            return self.activation(a)\n",
    "    \n",
    "    def activation(self, xs):\n",
    "        return np.array(list(map(lambda x: max(x,0.0), xs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7834df73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3191186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "dfc74b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self, code, num_of_layers, num_of_units_per_layer, X, y):\n",
    "        self.layers = []\n",
    "        self.loss = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.code = code\n",
    "        self.num_of_layers = num_of_layers\n",
    "        self.num_of_units_per_layer = num_of_units_per_layer\n",
    "        self.fitness = self.calcFitness()\n",
    "        \n",
    "    def decodeWeightsAddLayers(self):\n",
    "        for i in range(self.num_of_layers - 1):\n",
    "            limit = self.num_of_units_per_layer[i] * self.num_of_units_per_layer[i+1] + self.num_of_units_per_layer[i+1]\n",
    "            weights1 = np.array(self.code[:self.num_of_units_per_layer[i] * self.num_of_units_per_layer[i+1]])\n",
    "            bias = self.code[self.num_of_units_per_layer[i] * self.num_of_units_per_layer[i+1]:limit]\n",
    "            \n",
    "            weightsMatrix = weights1.reshape(self.num_of_units_per_layer[i+1], self.num_of_units_per_layer[i])\n",
    "            \n",
    "            isLastLayer = i == self.num_of_layers-2\n",
    "            \n",
    "            self.layers.append(DenseLayer('relu', isLastLayer, weightsMatrix, bias))\n",
    "            \n",
    "    def __lt__(self, other):\n",
    "        return self.fitness < other.fitness\n",
    "            \n",
    "    def calcFitness(self):\n",
    "        self.decodeWeightsAddLayers()\n",
    "        y_pred = self.all_results()\n",
    "        return self.mse(self.y, y_pred)\n",
    "        \n",
    "    def add_layer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "        \n",
    "    def mse(self, y_trues, y_preds):\n",
    "        return -np.sum((y_trues-y_preds)**2)/len(y_trues)\n",
    "        \n",
    "    def mae(self):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, x):\n",
    "        layer_output = x\n",
    "        for layer in self.layers:\n",
    "            layer_output = layer.get_output(layer_output)\n",
    "        \n",
    "        return layer_output\n",
    "    \n",
    "    def all_results(self):\n",
    "        results = []\n",
    "        for i in range(self.X.shape[0]):\n",
    "            results.append(self.predict(self.X[i])[0])\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "5d860746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "650"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_layers = 3 #including input and output\n",
    "num_of_units_per_layer = [13, 50, 1]\n",
    "\n",
    "numberOfWeights = 0\n",
    "for i in range(len(num_of_units_per_layer)-1):\n",
    "    numberOfWeights += num_of_units_per_layer[i] * num_of_units_per_layer[i+1]\n",
    "    \n",
    "numberOfWeights += sum(num_of_units_per_layer) - num_of_units_per_layer[0] # dodao bias za svaki unit\n",
    "    \n",
    "initWeights = np.random.uniform(low=-6.0, high=6.0, size=numberOfWeights)\n",
    "len(initWeights[:num_of_units_per_layer[i] * num_of_units_per_layer[i+1]])\n",
    "num_of_units_per_layer[0] * num_of_units_per_layer[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "b809dfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn = NeuralNetwork(initWeights, num_of_layers, num_of_units_per_layer, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a59ef86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection(population):\n",
    "    TOURNAMENT_SIZE = 20\n",
    "    bestFitness = float('-inf')\n",
    "    index = -1\n",
    "    for i in range(TOURNAMENT_SIZE):\n",
    "        \n",
    "        randomIndividual = random.randrange(len(population))\n",
    "        if population[randomIndividual].fitness > bestFitness:\n",
    "            bestFitness = population[randomIndividual].fitness\n",
    "            index = randomIndividual\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "3e13cc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(parent1, parent2, child1, child2):\n",
    "    breakpoint = random.randrange(len(parent1.code))\n",
    "    \n",
    "    child1.code[:breakpoint] = parent1.code[:breakpoint]\n",
    "    child2.code[:breakpoint] = parent2.code[:breakpoint]\n",
    "    \n",
    "    child1.code[breakpoint:] = parent2.code[breakpoint:]\n",
    "    child2.code[breakpoint:] = parent1.code[breakpoint:]\n",
    "    \n",
    "def crossover2(parent1, parent2, child1, child2):\n",
    "    for i in range(len(parent1.code)):\n",
    "        r = random.uniform(0.0, 1.0)\n",
    "        if r < 0.5:\n",
    "            child1.code[i] = parent1.code[i]\n",
    "            child2.code[i] = parent2.code[i]\n",
    "        else:\n",
    "            child1.code[i] = parent2.code[i]\n",
    "            child2.code[i] = parent1.code[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "edd7a49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def mutation(individual):\n",
    "    MUTATION_PROB = 0.001\n",
    "    for i in range(len(individual.code)):\n",
    "        if random.random() < MUTATION_PROB:\n",
    "            individual.code[i] = random.uniform(-1.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "b561dcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-119.50651858042384\n",
      "-95.64532993953576\n",
      "-78.09679488745655\n",
      "-51.45742425462074\n",
      "-38.352756728784136\n",
      "-31.38900090826903\n",
      "-29.394711611665105\n",
      "-27.530821505937958\n",
      "-25.935372764550014\n",
      "-23.667756773584927\n",
      "-21.559431612523763\n",
      "-20.66114511536902\n",
      "-20.074480826222633\n",
      "-19.457646686738066\n",
      "-18.169573658541914\n",
      "-17.767929864474382\n",
      "-16.843848503618073\n",
      "-16.529153579173958\n",
      "-16.12912165643657\n",
      "-15.155709843861398\n",
      "-14.812240566507427\n",
      "-14.2609010353996\n",
      "-13.6006951870346\n",
      "-13.405712572043125\n",
      "-13.316409813997687\n",
      "-13.036478549687926\n",
      "-12.90678163425471\n",
      "-12.51194528273878\n",
      "-12.38016482689692\n",
      "-12.221692228586441\n",
      "-12.079427535394657\n",
      "-11.903383098433565\n",
      "-11.721784586608539\n",
      "-11.632637669402618\n",
      "-11.332391941580056\n",
      "-11.203345115194265\n",
      "-11.045435527443038\n",
      "-10.893936777594234\n",
      "-10.799040852081506\n",
      "-10.798826716916588\n",
      "-10.771990908955708\n",
      "-10.754518716235946\n",
      "-10.621288484127415\n",
      "-10.405988266266661\n",
      "-10.334836632168965\n",
      "-10.28018506846079\n",
      "-10.234652262073022\n",
      "-10.212642505775802\n",
      "-10.112625225221894\n",
      "-10.0609708109665\n",
      "-10.023671498375453\n",
      "-9.914951639009432\n",
      "-9.840959718552938\n",
      "-9.760210627247673\n",
      "-9.702450972228766\n",
      "-9.67790759648836\n",
      "-9.65106712961802\n",
      "-9.51150188877478\n",
      "-9.464423358434313\n",
      "-9.371316122061728\n",
      "-9.358228891637966\n",
      "-9.304946940284818\n",
      "-9.236143065694762\n",
      "-9.14843285079061\n",
      "-9.075850304661468\n",
      "-8.860061960768235\n",
      "-8.824588164269255\n",
      "-8.659271141516188\n",
      "-8.645315354131734\n",
      "-8.553510583888356\n",
      "-8.538963613957286\n",
      "-8.469857556742285\n",
      "-8.447820086213833\n",
      "-8.44231023990647\n",
      "-8.426020886440464\n",
      "-8.426020886440464\n",
      "-8.395235946517081\n",
      "-8.358157012533377\n",
      "-8.327260529986683\n",
      "-8.306822735406923\n",
      "-8.227853525400302\n",
      "-8.219927595866539\n",
      "-8.141161303302104\n",
      "-8.119656160146034\n",
      "-8.095306461950344\n",
      "-8.065059307230301\n",
      "-8.029755629199794\n",
      "-8.015675689442958\n",
      "-8.003931476881089\n",
      "-7.977110097241091\n",
      "-7.948522350960288\n",
      "-7.9245058915231\n",
      "-7.91428586427497\n",
      "-7.850379177372199\n",
      "-7.842296216022001\n",
      "-7.799736241809751\n",
      "-7.761937877850982\n",
      "-7.747016990226009\n",
      "-7.725224873557547\n",
      "-7.722103367001569\n",
      "fitness: -7.722103367001569\n"
     ]
    }
   ],
   "source": [
    "POPULATION_SIZE = 100\n",
    "NUM_GENERATIONS = 100\n",
    "ELITISIM_SIZE = 10\n",
    "\n",
    "population = [NeuralNetwork(np.random.uniform(low=-1.0, high=1.0, size=numberOfWeights), num_of_layers, num_of_units_per_layer, X_train, y_train) for _ in range(POPULATION_SIZE)]\n",
    "newPopulation = [NeuralNetwork(np.random.uniform(low=-1.0, high=1.0, size=numberOfWeights), num_of_layers, num_of_units_per_layer, X_train, y_train) for _ in range(POPULATION_SIZE)]\n",
    "\n",
    "for i in range(NUM_GENERATIONS):\n",
    "    population.sort(reverse=True)\n",
    "    newPopulation[:ELITISIM_SIZE] = population[:ELITISIM_SIZE]\n",
    "    for j in range(ELITISIM_SIZE, POPULATION_SIZE, 2):\n",
    "        parent1Index = selection(population) # OK\n",
    "        parent2Index = selection(population) # OK\n",
    "        \n",
    "        crossover2(population[parent1Index], population[parent2Index], newPopulation[j], newPopulation[j+1]) # OK\n",
    "\n",
    "        mutation(newPopulation[j])\n",
    "        mutation(newPopulation[j+1])\n",
    "\n",
    "        newPopulation[j] = NeuralNetwork(newPopulation[j].code, num_of_layers, num_of_units_per_layer, X_train, y_train)\n",
    "        newPopulation[j+1] = NeuralNetwork(newPopulation[j+1].code, num_of_layers, num_of_units_per_layer, X_train, y_train)\n",
    "        \n",
    "    population = newPopulation\n",
    "    print(max(population).fitness)\n",
    "    \n",
    "bestIndividual = max(population)\n",
    "print(f'fitness: {bestIndividual.fitness}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "147e158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "nn1 = NeuralNetwork(bestIndividual.code, num_of_layers, num_of_units_per_layer, X_test, y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "36d106c0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7dac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(102):\n",
    "    print(y_test[i], nn1.all_results()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d19950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b930ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c683bf3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
