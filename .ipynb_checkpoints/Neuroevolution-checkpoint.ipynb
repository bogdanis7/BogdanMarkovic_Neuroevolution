{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e0a6f9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bd2038e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import boston_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d10716b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X_train)\n",
    "# X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "# X_train.shape\n",
    "# X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8791baf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1154, 18)\n",
      "(495, 18)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./Life Expectancy Data.csv')\n",
    "data\n",
    "data = data.drop(['Country'], axis=1)\n",
    "data = data.drop(['Status'], axis=1)\n",
    "data = data.drop(['Year'], axis=1)\n",
    "data = data.dropna()\n",
    "\n",
    "X = data.drop(data.columns[0], axis=1).to_numpy()\n",
    "X\n",
    "y = data.iloc[:, 0].to_numpy()\n",
    "y\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=456)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d7770328",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer:\n",
    "    def __init__(self, activation_function, isLastLayer, weightsMatrix, bias):\n",
    "        self.isLastLayer = isLastLayer\n",
    "        self.activation_function = activation_function\n",
    "        self.weights = weightsMatrix\n",
    "        self.bias = bias\n",
    "    \n",
    "    def get_output(self, layer_input):\n",
    "        self.layer_input = layer_input\n",
    "        \n",
    "        if self.isLastLayer:\n",
    "            return np.dot(self.weights, self.layer_input) + self.bias\n",
    "        else:\n",
    "            a = np.dot(self.weights, self.layer_input) + self.bias\n",
    "            return self.relu(a)\n",
    "    \n",
    "    def relu(self, xs):\n",
    "        return np.array(list(map(lambda x: max(x,0.0), xs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "de6fc24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self, code, num_of_layers, num_of_units_per_layer, X, y):\n",
    "        self.layers = []\n",
    "        self.loss = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.code = code\n",
    "        self.num_of_layers = num_of_layers\n",
    "        self.num_of_units_per_layer = num_of_units_per_layer\n",
    "        self.fitness = self.calcFitness()\n",
    "        \n",
    "    def decodeWeightsAddLayers(self):\n",
    "        for i in range(self.num_of_layers - 1):\n",
    "            limit = self.num_of_units_per_layer[i] * self.num_of_units_per_layer[i+1] + self.num_of_units_per_layer[i+1]\n",
    "            weights1 = np.array(self.code[:self.num_of_units_per_layer[i] * self.num_of_units_per_layer[i+1]])\n",
    "            bias = self.code[self.num_of_units_per_layer[i] * self.num_of_units_per_layer[i+1]:limit]\n",
    "            \n",
    "            weightsMatrix = weights1.reshape(self.num_of_units_per_layer[i+1], self.num_of_units_per_layer[i])\n",
    "            \n",
    "            isLastLayer = i == self.num_of_layers-2\n",
    "            \n",
    "            self.layers.append(DenseLayer('relu', isLastLayer, weightsMatrix, bias))\n",
    "            \n",
    "    def __lt__(self, other):\n",
    "        return self.fitness < other.fitness\n",
    "            \n",
    "    def calcFitness(self):\n",
    "        self.decodeWeightsAddLayers()\n",
    "        y_pred = self.all_results()\n",
    "        return -self.mae(self.y, y_pred)\n",
    "        \n",
    "    def add_layer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "        \n",
    "    def mse(self, y_trues, y_preds):\n",
    "        return np.sum((y_trues-y_preds)**2)/len(y_trues)\n",
    "        \n",
    "    def mae(self, y_trues, y_preds):\n",
    "        return np.sum(abs(y_trues-y_preds))/len(y_trues)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        layer_output = x\n",
    "        for layer in self.layers:\n",
    "            layer_output = layer.get_output(layer_output)\n",
    "        \n",
    "        return layer_output\n",
    "    \n",
    "    def all_results(self):\n",
    "        results = []\n",
    "        for i in range(self.X.shape[0]):\n",
    "            results.append(self.predict(self.X[i])[0])\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8068c729",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_layers = 4 #including input and output\n",
    "num_of_units_per_layer = [18, 20, 20, 1]\n",
    "\n",
    "numberOfWeights = 0\n",
    "for i in range(len(num_of_units_per_layer)-1):\n",
    "    numberOfWeights += num_of_units_per_layer[i] * num_of_units_per_layer[i+1]\n",
    "    \n",
    "numberOfWeights += sum(num_of_units_per_layer) - num_of_units_per_layer[0] # dodao bias za svaki unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e2f3b789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection(population):\n",
    "    TOURNAMENT_SIZE = 16\n",
    "    bestFitness = float('-inf')\n",
    "    index = -1\n",
    "    for i in range(TOURNAMENT_SIZE):\n",
    "        \n",
    "        randomIndividual = random.randrange(len(population))\n",
    "        if population[randomIndividual].fitness > bestFitness:\n",
    "            bestFitness = population[randomIndividual].fitness\n",
    "            index = randomIndividual\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "40c84345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(parent1, parent2, child1, child2):\n",
    "    breakpoint = random.randrange(len(parent1.code))\n",
    "    \n",
    "    child1.code[:breakpoint] = parent1.code[:breakpoint]\n",
    "    child2.code[:breakpoint] = parent2.code[:breakpoint]\n",
    "    \n",
    "    child1.code[breakpoint:] = parent2.code[breakpoint:]\n",
    "    child2.code[breakpoint:] = parent1.code[breakpoint:]\n",
    "    \n",
    "def crossover2(parent1, parent2, child1, child2):\n",
    "    for i in range(len(parent1.code)):\n",
    "        r = random.uniform(0.0, 1.0)\n",
    "        if r < 0.5:\n",
    "            child1.code[i] = parent1.code[i]\n",
    "            child2.code[i] = parent2.code[i]\n",
    "        else:\n",
    "            child1.code[i] = parent2.code[i]\n",
    "            child2.code[i] = parent1.code[i]\n",
    "            \n",
    "def two_point_crossover(parent1, parent2, child1, child2):\n",
    "    breakpoint1 = random.randrange(1, len(parent1.code))\n",
    "    breakpoint2 = random.randrange(1, len(parent1.code) - 1)\n",
    "    if breakpoint2 >= breakpoint1:\n",
    "        breakpoint2 += 1\n",
    "    else:\n",
    "        breakpoint1, breakpoint2 = breakpoint2, breakpoint1\n",
    "        \n",
    "    child1.code[:breakpoint1] = parent1.code[:breakpoint1]\n",
    "    child1.code[breakpoint1:breakpoint2] = parent2.code[breakpoint1:breakpoint2]\n",
    "    child1.code[breakpoint2:] = parent1.code[breakpoint2:]\n",
    "    \n",
    "    child2.code[:breakpoint1] = parent2.code[:breakpoint1]\n",
    "    child2.code[breakpoint1:breakpoint2] = parent1.code[breakpoint1:breakpoint2]\n",
    "    child2.code[breakpoint2:] = parent2.code[breakpoint2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b9802210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def mutation(individual, best):\n",
    "    MUTATION_PROB = 0.007 * (individual.fitness/best.fitness)**2\n",
    "    for i in range(len(individual.code)):\n",
    "        if random.random() < MUTATION_PROB:\n",
    "            individual.code[i] = random.uniform(-1.2, 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909456c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-42.94961507057184\n",
      "-40.19309427251112\n",
      "-35.68157363154927\n",
      "-35.68157363154927\n",
      "-33.50726124136631\n",
      "-31.906666411203705\n",
      "-23.984968978607856\n",
      "-23.984968978607856\n",
      "-20.130606633704488\n",
      "-18.554428403567155\n",
      "-18.249398720608742\n",
      "-17.31682277033197\n",
      "-17.31682277033197\n",
      "-16.25760968943898\n",
      "-15.990630268828514\n",
      "-14.989509775524098\n",
      "-14.573465005714475\n",
      "-14.140451857104201\n",
      "-14.073811812222337\n",
      "-13.645372466313034\n",
      "-13.313241598670517\n",
      "-13.313241598670517\n",
      "-12.99971751848066\n",
      "-12.724608557175902\n",
      "-12.135824949775497\n"
     ]
    }
   ],
   "source": [
    "POPULATION_SIZE = 100\n",
    "NUM_GENERATIONS = 300\n",
    "ELITISM_SIZE = 16\n",
    "\n",
    "population = [NeuralNetwork(np.random.uniform(low=-1.2, high=1.2, size=numberOfWeights), num_of_layers, num_of_units_per_layer, X_train, y_train) for _ in range(POPULATION_SIZE)]\n",
    "newPopulation = [NeuralNetwork(np.random.uniform(low=-1.2, high=1.2, size=numberOfWeights), num_of_layers, num_of_units_per_layer, X_train, y_train) for _ in range(POPULATION_SIZE)]\n",
    "bestMAEs = []\n",
    "for i in range(NUM_GENERATIONS):\n",
    "    population.sort(reverse=True)\n",
    "    newPopulation[:ELITISM_SIZE] = population[:ELITISM_SIZE]\n",
    "    for j in range(ELITISM_SIZE, POPULATION_SIZE, 2):\n",
    "        parent1Index = selection(population[ELITISM_SIZE:])\n",
    "        parent2Index = selection(population[ELITISM_SIZE:])\n",
    "        \n",
    "        crossover(population[parent1Index], population[parent2Index], newPopulation[j], newPopulation[j+1])\n",
    "\n",
    "        mutation(newPopulation[j], max(population))\n",
    "        mutation(newPopulation[j+1], max(population))\n",
    "\n",
    "        newPopulation[j] = NeuralNetwork(newPopulation[j].code, num_of_layers, num_of_units_per_layer, X_train, y_train)\n",
    "        newPopulation[j+1] = NeuralNetwork(newPopulation[j+1].code, num_of_layers, num_of_units_per_layer, X_train, y_train)\n",
    "        \n",
    "    population = newPopulation\n",
    "    print(max(population).fitness)\n",
    "    bestMAEs.append(-max(population).fitness)\n",
    "    \n",
    "bestIndividual = max(population)\n",
    "print(f'fitness: {bestIndividual.fitness}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa74610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n",
    "# print(bestIndividual.fitness)\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X_train)\n",
    "# X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "nn1 = NeuralNetwork(bestIndividual.code, num_of_layers, num_of_units_per_layer, X_test, y_test)\n",
    "nn1.fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d7b40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(range(100), bestMAEs)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e824f645",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "debe7a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.2 13.086333134299618\n",
      "18.8 15.148307763068106\n",
      "19.0 21.107061097522546\n",
      "27.0 32.53899537072529\n",
      "22.2 24.9678085404926\n",
      "24.5 16.91911790745808\n",
      "31.2 25.85943517862848\n",
      "22.9 22.41618343233399\n",
      "20.5 20.44189340379536\n",
      "23.2 21.094602259923096\n",
      "18.6 17.602257304981155\n",
      "14.5 16.973778173531763\n",
      "17.8 16.96045612896985\n",
      "50.0 40.780620368255484\n",
      "20.8 15.266582878359296\n",
      "24.3 18.4331969079355\n",
      "24.2 24.759661477069223\n",
      "19.8 20.552992372618274\n",
      "19.1 17.2101321846823\n",
      "22.7 20.762887149444627\n",
      "12.0 12.545877609470539\n",
      "10.2 18.93825509640731\n",
      "20.0 18.91085214568212\n",
      "18.5 16.075741109597168\n",
      "20.9 18.87927942954752\n",
      "23.0 22.97281504849157\n",
      "27.5 32.780039135976054\n",
      "30.1 25.69284468766764\n",
      "9.5 14.018541980029203\n",
      "22.0 20.42620440488628\n",
      "21.2 17.361851839379504\n",
      "14.1 18.271874229004084\n",
      "33.1 32.293857465309145\n",
      "23.4 23.929727517156234\n",
      "20.1 17.95940759605658\n",
      "7.4 9.616437417951975\n",
      "15.4 13.75559941414657\n",
      "23.8 16.52896428604726\n",
      "20.1 18.646829921114495\n",
      "24.5 25.113203630860944\n",
      "33.0 31.152322313154237\n",
      "28.4 28.505375382045383\n",
      "14.1 13.533299681129925\n",
      "46.7 35.30735027339163\n",
      "32.5 32.26566058147383\n",
      "29.6 23.887031328588478\n",
      "28.4 27.1193809211242\n",
      "19.8 15.226207653066208\n",
      "20.2 18.60732474994001\n",
      "25.0 20.148067282758173\n",
      "35.4 32.47403577409051\n",
      "20.3 18.202326323655853\n",
      "9.7 12.653554783466236\n",
      "14.5 15.756401776550694\n",
      "34.9 35.812567782867156\n",
      "26.6 27.767220120038996\n",
      "7.2 12.639294840425075\n",
      "50.0 46.826799629367855\n",
      "32.4 33.33403999906257\n",
      "21.6 26.111531507309355\n",
      "29.8 22.566890431153322\n",
      "13.1 15.6203113588288\n",
      "27.5 16.28307935395074\n",
      "21.2 15.739121243587952\n",
      "23.1 22.42875338698098\n",
      "21.9 21.22342925237075\n",
      "13.0 11.697900206757726\n",
      "23.2 22.234734609059522\n",
      "8.1 12.843426872401935\n",
      "5.6 9.421151794784175\n",
      "21.7 21.514230856847156\n",
      "29.6 26.138779475244778\n",
      "19.6 22.50897541501606\n",
      "7.0 14.545622772046345\n",
      "26.4 23.580580916970863\n",
      "18.9 19.4128439595514\n",
      "20.9 19.719380371191185\n",
      "28.1 20.565941390887268\n",
      "35.4 34.26555947910194\n",
      "10.2 11.510605852698957\n",
      "24.3 18.77553564818035\n",
      "43.1 39.267517739253265\n",
      "17.6 15.807678787217434\n",
      "15.4 13.092110568324262\n",
      "16.2 16.819672878654305\n",
      "27.1 19.80088603500821\n",
      "21.4 17.430391060049725\n",
      "21.5 23.10817899337191\n",
      "22.4 21.173024153497586\n",
      "25.0 28.631798976333627\n",
      "16.6 22.105940387123248\n",
      "18.6 17.938143887788954\n",
      "22.0 25.998443239287116\n",
      "42.8 35.842548991959255\n",
      "35.1 34.99211228253903\n",
      "21.5 18.33649736723347\n",
      "36.0 37.660563170922245\n",
      "21.9 45.605672243675144\n",
      "24.1 25.26355309195083\n",
      "50.0 46.97210619786775\n",
      "26.7 34.68863893102738\n",
      "25.0 19.064978902402554\n"
     ]
    }
   ],
   "source": [
    "for i in range(102):\n",
    "    print(y_test[i], nn1.all_results()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4357cd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 68.5345 - mae: 68.5345 - val_loss: 68.7544 - val_mae: 68.7544\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 67.4568 - mae: 67.4568 - val_loss: 67.5122 - val_mae: 67.5122\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 65.8316 - mae: 65.8316 - val_loss: 65.5249 - val_mae: 65.5249\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 63.1152 - mae: 63.1152 - val_loss: 62.1246 - val_mae: 62.1246\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 58.4212 - mae: 58.4212 - val_loss: 56.4140 - val_mae: 56.4140\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 51.2290 - mae: 51.2290 - val_loss: 48.0562 - val_mae: 48.0562\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 42.2026 - mae: 42.2026 - val_loss: 38.6055 - val_mae: 38.6055\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 33.7628 - mae: 33.7628 - val_loss: 29.6663 - val_mae: 29.6663\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 26.0173 - mae: 26.0173 - val_loss: 22.7863 - val_mae: 22.7863\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 20.2920 - mae: 20.2920 - val_loss: 18.2709 - val_mae: 18.2709\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 16.8892 - mae: 16.8892 - val_loss: 15.1180 - val_mae: 15.1180\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 14.4713 - mae: 14.4713 - val_loss: 12.8904 - val_mae: 12.8904\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 12.9010 - mae: 12.9010 - val_loss: 11.3740 - val_mae: 11.3740\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 11.8188 - mae: 11.8188 - val_loss: 10.5868 - val_mae: 10.5868\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 11.0984 - mae: 11.0984 - val_loss: 9.8830 - val_mae: 9.8830\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 10.5370 - mae: 10.5370 - val_loss: 9.4329 - val_mae: 9.4329\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 10.0337 - mae: 10.0337 - val_loss: 8.9875 - val_mae: 8.9875\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.6659 - mae: 9.6659 - val_loss: 8.7038 - val_mae: 8.7038\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.3123 - mae: 9.3123 - val_loss: 8.4085 - val_mae: 8.4085\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.9919 - mae: 8.9919 - val_loss: 8.1643 - val_mae: 8.1643\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.7061 - mae: 8.7061 - val_loss: 8.0013 - val_mae: 8.0013\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.4663 - mae: 8.4663 - val_loss: 7.8464 - val_mae: 7.8464\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 8.2024 - mae: 8.2024 - val_loss: 7.6526 - val_mae: 7.6526\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.9577 - mae: 7.9577 - val_loss: 7.4241 - val_mae: 7.4241\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.7367 - mae: 7.7367 - val_loss: 7.3050 - val_mae: 7.3050\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.5250 - mae: 7.5250 - val_loss: 7.1281 - val_mae: 7.1281\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.2998 - mae: 7.2998 - val_loss: 6.9940 - val_mae: 6.9940\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 7.0850 - mae: 7.0850 - val_loss: 6.7779 - val_mae: 6.7779\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.9048 - mae: 6.9048 - val_loss: 6.6918 - val_mae: 6.6918\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.7099 - mae: 6.7099 - val_loss: 6.4413 - val_mae: 6.4413\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.5257 - mae: 6.5257 - val_loss: 6.3836 - val_mae: 6.3836\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.3814 - mae: 6.3814 - val_loss: 6.2598 - val_mae: 6.2598\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.2430 - mae: 6.2430 - val_loss: 6.0418 - val_mae: 6.0418\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 6.0438 - mae: 6.0438 - val_loss: 5.9033 - val_mae: 5.9033\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.9092 - mae: 5.9092 - val_loss: 5.8433 - val_mae: 5.8433\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.7719 - mae: 5.7719 - val_loss: 5.6513 - val_mae: 5.6513\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.6401 - mae: 5.6401 - val_loss: 5.4704 - val_mae: 5.4704\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.5130 - mae: 5.5130 - val_loss: 5.4144 - val_mae: 5.4144\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.3693 - mae: 5.3693 - val_loss: 5.1895 - val_mae: 5.1895\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.2725 - mae: 5.2725 - val_loss: 5.2273 - val_mae: 5.2273\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 5.1374 - mae: 5.1374 - val_loss: 5.0047 - val_mae: 5.0047\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.9937 - mae: 4.9937 - val_loss: 4.8250 - val_mae: 4.8250\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.8535 - mae: 4.8535 - val_loss: 4.7365 - val_mae: 4.7365\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.7313 - mae: 4.7313 - val_loss: 4.5789 - val_mae: 4.5789\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.6399 - mae: 4.6399 - val_loss: 4.5584 - val_mae: 4.5584\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.5441 - mae: 4.5441 - val_loss: 4.5009 - val_mae: 4.5009\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.4386 - mae: 4.4386 - val_loss: 4.3300 - val_mae: 4.3300\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.3144 - mae: 4.3144 - val_loss: 4.2874 - val_mae: 4.2874\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.2493 - mae: 4.2493 - val_loss: 4.1717 - val_mae: 4.1717\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.1662 - mae: 4.1662 - val_loss: 4.0465 - val_mae: 4.0465\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.0858 - mae: 4.0858 - val_loss: 4.1069 - val_mae: 4.1069\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.9981 - mae: 3.9981 - val_loss: 3.9288 - val_mae: 3.9288\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8861 - mae: 3.8861 - val_loss: 3.8101 - val_mae: 3.8101\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8094 - mae: 3.8094 - val_loss: 3.7530 - val_mae: 3.7530\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.7218 - mae: 3.7218 - val_loss: 3.6443 - val_mae: 3.6443\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.6419 - mae: 3.6419 - val_loss: 3.5882 - val_mae: 3.5882\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.5793 - mae: 3.5793 - val_loss: 3.5385 - val_mae: 3.5385\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.5144 - mae: 3.5144 - val_loss: 3.4835 - val_mae: 3.4835\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.4493 - mae: 3.4493 - val_loss: 3.5331 - val_mae: 3.5331\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.4419 - mae: 3.4419 - val_loss: 3.3727 - val_mae: 3.3727\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.3501 - mae: 3.3501 - val_loss: 3.3579 - val_mae: 3.3579\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.2889 - mae: 3.2889 - val_loss: 3.3154 - val_mae: 3.3154\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.2653 - mae: 3.2653 - val_loss: 3.3060 - val_mae: 3.3060\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.1700 - mae: 3.1700 - val_loss: 3.2587 - val_mae: 3.2587\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.1783 - mae: 3.1783 - val_loss: 3.1962 - val_mae: 3.1962\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.0899 - mae: 3.0899 - val_loss: 3.1680 - val_mae: 3.1680\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.0661 - mae: 3.0661 - val_loss: 3.1443 - val_mae: 3.1443\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.0453 - mae: 3.0453 - val_loss: 3.0844 - val_mae: 3.0844\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.9798 - mae: 2.9798 - val_loss: 3.0996 - val_mae: 3.0996\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.9307 - mae: 2.9307 - val_loss: 3.1203 - val_mae: 3.1203\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.8994 - mae: 2.8994 - val_loss: 2.9999 - val_mae: 2.9999\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.8522 - mae: 2.8522 - val_loss: 3.0392 - val_mae: 3.0392\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.8372 - mae: 2.8372 - val_loss: 2.9798 - val_mae: 2.9798\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.8219 - mae: 2.8219 - val_loss: 2.9428 - val_mae: 2.9428\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.7630 - mae: 2.7630 - val_loss: 2.9349 - val_mae: 2.9349\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.7438 - mae: 2.7438 - val_loss: 2.9039 - val_mae: 2.9039\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.6832 - mae: 2.6832 - val_loss: 2.8810 - val_mae: 2.8810\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.6569 - mae: 2.6569 - val_loss: 2.9349 - val_mae: 2.9349\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.6549 - mae: 2.6549 - val_loss: 2.8216 - val_mae: 2.8216\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.5966 - mae: 2.5966 - val_loss: 2.8413 - val_mae: 2.8413\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.5580 - mae: 2.5580 - val_loss: 2.8440 - val_mae: 2.8440\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.5665 - mae: 2.5665 - val_loss: 2.7626 - val_mae: 2.7626\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.5144 - mae: 2.5144 - val_loss: 2.7372 - val_mae: 2.7372\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.4815 - mae: 2.4815 - val_loss: 2.7332 - val_mae: 2.7332\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.4691 - mae: 2.4691 - val_loss: 2.8140 - val_mae: 2.8140\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.4579 - mae: 2.4579 - val_loss: 2.7154 - val_mae: 2.7154\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.4203 - mae: 2.4203 - val_loss: 2.7220 - val_mae: 2.7220\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.3849 - mae: 2.3849 - val_loss: 2.6939 - val_mae: 2.6939\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.3800 - mae: 2.3800 - val_loss: 2.6841 - val_mae: 2.6841\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.3433 - mae: 2.3433 - val_loss: 2.6579 - val_mae: 2.6579\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.3330 - mae: 2.3330 - val_loss: 2.7063 - val_mae: 2.7063\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.3322 - mae: 2.3322 - val_loss: 2.5995 - val_mae: 2.5995\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.2789 - mae: 2.2789 - val_loss: 2.6097 - val_mae: 2.6097\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.2863 - mae: 2.2863 - val_loss: 2.7926 - val_mae: 2.7926\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.2902 - mae: 2.2902 - val_loss: 2.5590 - val_mae: 2.5590\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.2770 - mae: 2.2770 - val_loss: 2.5688 - val_mae: 2.5688\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.1969 - mae: 2.1969 - val_loss: 2.6604 - val_mae: 2.6604\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.2119 - mae: 2.2119 - val_loss: 2.5886 - val_mae: 2.5886\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.1840 - mae: 2.1840 - val_loss: 2.5324 - val_mae: 2.5324\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.1836 - mae: 2.1836 - val_loss: 2.4935 - val_mae: 2.4935\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim=X_train.shape[1], units=20, activation='relu'))\n",
    "model.add(Dense(input_dim=X_train.shape[1], units=20, activation='relu'))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mae', metrics=['mae'])\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9fb46fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 596us/step - loss: 2.6455 - mae: 2.6455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.6455273628234863, 2.6455273628234863]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1bb1df20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f40c3de490>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history['mae'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
